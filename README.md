## DL project

–°–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ: [FAT2019](https://www.kaggle.com/c/freesound-audio-tagging-2019)

–ë–µ–π–∑–ª–∞–π–Ω: https://github.com/m12sl/kaggle-freesound-2019-baseline
#
### **LSML**:

–í—Å—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –∏–∑ [readme.md](https://github.com/m12sl/kaggle-freesound-2019-baseline/blob/master/README.md)  –≤—ã–ø–æ–ª–Ω–µ–Ω–∞.
1.	–ù–∞—É—á–∏–ª–∏—Å—å –∑–∞–ø—É—Å–∫–∞—Ç—å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ (—á–µ—Ä–µ–∑ tmux)
```
# —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–æ–≤–∞—Ç—å –∫–æ–¥
–ß–µ—Ä–µ–∑ tmux
# –∑–∞–π—Ç–∏ –≤ –Ω—É–∂–Ω—É—é –ø–∞–ø–∫—É
cd kaggle-freesound-2019-baseline/
#–≤–≤–µ—Å—Ç–∏
python main.py --outpath ./runs/
```
2.	C–º–æ—Ç—Ä–µ—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ –≤ tensorboard 
```
–ß–µ—Ä–µ–∑ tmux
# –∑–∞–π—Ç–∏ –≤ –ø–∞–ø–∫—É —Å –∑–∞–ø—É—Å–∫–∞–º–∏ –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å TB.  
cd kaggle-freesound-2019-baseline/runs/
CUDA_VISIBLE_DEVICES= tensorboard --logdir=./
# –ù–∞ —Å–≤–æ–µ–π –º–∞—à–∏–Ω–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å
ssh -L 9009:localhost:6006 ubuntu@[public_server_ip]
# –∑–∞–π—Ç–∏ –≤ –±—Ä–∞—É–∑–µ—Ä–µ –Ω–∞ http://localhost:9009 
```
3.	–û—Ç–ª–∞–∂–∏–≤–∞—Ç—å —Å–∫—Ä–∏–ø—Ç—ã. 
```
–ß–µ—Ä–µ–∑ tmux
./start_notebook.sh
# –∑–∞–π—Ç–∏ –≤ –±—Ä–∞—É–∑–µ—Ä–µ –Ω–∞ https://[public_server_ip]:9999/tree/kaggle-freesound-2019-baseline
```
4.	–û—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ª—É—á—à–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã –∫–∞–∫ –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ Kaggle —á–µ—Ä–µ–∑ [Kaggle.api](https://github.com/Kaggle/kaggle-api) (_–ø—Ä–∏–º–µ—Ä –¥–ª—è runs/0_)
```
#–ù–∞ —Å–µ—Ä–≤–µ—Ä–µ
kaggle datasets init -p ~/kaggle-freesound-2019-baseline/runs/0
cd ~/kaggle-freesound-2019-baseline/runs/0
vim dataset-metadata.json (–≤–≤–µ—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞)
kaggle datasets create -p ./

#–î–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
kaggle datasets version -p ./ -m "Updated data"
```
5.	–°–∞–±–º–∏—Ç–∏—Ç—å –æ—Ç–≤–µ—Ç—ã —á–µ—Ä–µ–∑ —Å–∫—Ä–∏–ø—Ç—ã –≤ –∫–µ—Ä–Ω–µ–ª–µ. –ò —ç—Ç–æ –≤—Å–µ –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ 2 –ø–∏—Ç–æ–Ω ü§î
```
* —Å–æ–∑–¥–∞—Ç—å –ø—Ä–∏–≤–∞—Ç–Ω—ã–π –∫–µ—Ä–Ω–µ–ª —Å –∫–æ–¥–æ–º –∏–∑ kernel_infer.py
* –∑–∞–ª–∏—Ç—å –ª—É—á—à–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç best.pth –≤ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
* –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—É—Ç–∏, –∑–∞–ø—É—Å—Ç–∏—Ç—å, –¥–æ–∂–¥–∞—Ç—å—Å—è –ø—Ä–æ—Å—á–µ—Ç–∞ –∏ –Ω–∞ –≤–∫–ª–∞–¥–∫–µ Outputs –∑–∞—Å–∞–±–º–∏—Ç–∏—Ç—å –æ—Ç–≤–µ—Ç—ã
```
–î–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –Ω–∞–∫–ª–∞–¥–æ–∫ —Å–æ 2 –ø–∏—Ç–æ–Ω–æ–º, –∑–∞–ø–∏—Å—ã–≤–∞–ª—Å—è –Ω–æ–≤—ã–π chkp
```
#–ù–∞ —Å–µ—Ä–≤–µ—Ä–µ
cd
python 
import torch
path = './kaggle-freesound-2019-baseline/runs/1/last.pth'
x = torch.load(path)
torch.save(x['model_state_dict'],'./kaggle-freesound-2019-baseline/runs/0/last1.pth')
```
#
### **DL**:

1. –î–ª—è –Ω–∞—á–∞–ª–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –±—ã–ª–æ –¥–æ–±–∞–≤–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ `best.pth` –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –Ω–µ –∑–∞–±–æ—Ç–∏—Ç—å—Å—è –æ –≤–æ–∑–º–æ–∂–Ω–æ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–∏ —Å–µ—Ç–∫–∏ –∏ —Å–ø–æ–∫–æ–π–Ω–æ —Å–ø–∞—Ç—å –Ω–æ—á—å—é üò¥, –ø–æ–∫–∞ —Å–µ—Ç—å –∑–∞–Ω–∏–º–∞–µ—Ç—Å—è –ø–æ–ª–µ–∑–Ω–æ—Å—Ç—è–º–∏, –∞ –∏–º–µ–Ω–Ω–æ - —É—á–∏—Ç—Å—è.
2. –ó–∞–ø—É—Å—Ç–∏–ª–∞ –±–µ–π–∑–ª–∞–π–Ω, –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ–Ω–∏–º–∞—Ç—å –æ—Ç —á–µ–≥–æ –Ω–∞–º –æ—Ç—Ç–∞–ª–∫–∏–≤–∞—Ç—å—Å—è –∏ —Å —á–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å. –ö—Ä–æ–º–µ —ç—Ç–æ–≥–æ, –≤—Å–µ –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ —É–ª—É—á—à–µ–Ω–∏—è, –º–æ–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Å —ç—Ç–æ–π –º–æ–¥–µ–ª—å—é —Å –ø–æ–º–æ—â—å—é tensorboard, –∑–∞—á–∞—Å—Ç—É—é –Ω–µ–¥–æ–æ–±—É—á–∞—è –º–æ–¥–µ–ª—å. 
3. –ò–¥–µ–∏ –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏

 ‚úÖ –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
  ```
  parser.add_argument('--epochs', default=30)
  ```
 ‚úÖ –ë–æ–ª—å—à–∏–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ 
  ```
  parser.add_argument('--batch_size', default=64)
  ```
 ‚úÖ –ü–æ–º–µ–Ω—è—Ç—å `learning rate`
 
 –ü—Ä–æ–±–æ–≤–∞–ª–∞ —Ä–∞–∑–Ω—ã–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è, –≤ –∏—Ç–æ–≥–µ, –æ—Å—Ç–∞–Ω–æ–≤–∏–ª–∞—Å—å –Ω–∞ 
  ```
  scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)
  ```
  <img src=https://github.com/krDaria/freesound_audio_tagging_2019/raw/master/images/loss_change.png height="300">
  
  _–†–µ–∑—É–ª—å—Ç–∞—Ç_: <img src=https://github.com/krDaria/freesound_audio_tagging_2019/raw/master/images/loss_lrap_1.png height="300">
 
 –†–µ–∑—É–ª—å—Ç–∞—Ç —Ö–æ—Ä–æ—à–∏–π, –≤–∏–¥–∏–º, —á—Ç–æ –ø—Ä–∏–±–∞–≤–∏–ª–∏ —Ç–æ—á–Ω–æ—Å—Ç—å

–î–∞–ª–µ–µ, —è –ø—Ä–æ–±–æ–≤–∞–ª–∞ –º–µ–Ω—è—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å–µ—Ç–∏:
  
  ‚ùå –ò–∑–º–µ–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ `ReLU -> Sigmoid`
  
  ‚ùå –ü–æ—Å—Ç–∞–≤–∏—Ç—å `batchnorm` –ø–æ—Å–ª–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ 
  
  
  ‚ùå –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä `dropout`
  ```
  self.fc = nn.Sequential(
            nn.Dropout(0.6),
            nn.Linear(128, num_classes),
         )
  ```
  ‚ùå –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è fc
  ```
  self.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(512 * block.expansion, num_classes),
            nn.PReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.1),
            nn.Linear(128, num_classes),
         )
  ```
  ‚ùå –ò–∑–º–µ–Ω–∏—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö (–∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –§—É—Ä—å–µ, —Ä–∞–∑–º–µ—Ä –Ω–∞–ª–æ–∂–µ–Ω–∏—è –æ–∫–Ω–∞)
  ```
  n_fft, hop
  ```
  _–†–µ–∑—É–ª—å—Ç–∞—Ç_: <img src=https://github.com/krDaria/freesound_audio_tagging_2019/raw/master/images/loss_lrap_2.png height="300">
  
  –î–∞–Ω–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –Ω–µ –ø—Ä–∏–Ω–µ—Å–ª–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ validate
  
  ‚úÖ –î–æ–±–∞–≤–∏—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é [`mixup`](https://www.inference.vc/mixup-data-dependent-data-augmentation/)
  ```
  # mixup function
  def mixup_data(x, y, alpha=1.0):
      indices = torch.randperm(x.size()[0])
      x2 = x[indices]
      y2 = y[indices]

      mixed_x = lam * x + (1 - lam) * x2
      mixed_y = lam * y + (1 - lam) * y2
      return mixed_x, mixed_y, lam
  ```
  
  ‚úÖ –ò–∑–º–µ–Ω–∏—Ç—å  `loss`
  
  –ë—É–¥–µ–º —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å `binary_cross_entropy_with_logits` loss —Å `binary_cross_entropy` –Ω–∞ –æ—Ç–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
  ```
  out1 = torch.tensor(minmax_scale(out.reshape(-1).cpu().detach().numpy(), (0.00001,0.99999)))
  t1 = torch.tensor(minmax_scale(targets.reshape(-1).cpu().detach().numpy(), (0.00001,0.99999)))
  out1, t1 = map(Variable, (out1, t1))

  loss = F.binary_cross_entropy_with_logits(out, targets) + F.binary_cross_entropy(out1, t1)
  ```
  _–†–µ–∑—É–ª—å—Ç–∞—Ç_: 
  
  <img src=https://github.com/krDaria/freesound_audio_tagging_2019/raw/master/images/lwlrap.png height="300">
  
  –†–µ–∑—É–ª—å—Ç–∞—Ç —Ö–æ—Ä–æ—à–∏–π, –≤–∏–¥–∏–º, —á—Ç–æ –ø—Ä–∏–±–∞–≤–∏–ª–∏ —Ç–æ—á–Ω–æ—Å—Ç—å (–ø—Ä–∏–≤–µ–¥–µ–Ω—ã –≥—Ä–∞—Ñ–∏–∫–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π —á–∞—Å—Ç–∏ –≤—ã–±–æ—Ä–∫–∏, —Å–∏–Ω–∏–π - —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏, –≥–æ–ª—É–±–æ–π - —Å –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–º –ª–æ—Å—Å–æ–º, –∫—Ä–∞—Å–Ω—ã–π - –±–µ–π–∑–ª–∞–π–Ω, —Ä–æ–∑–æ–≤—ã–π - —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏ –≤—ã—à–µ)
  
  Public Score: 0.529 (baseline - 0.51)
  
  - _–ù–µ —É—Å–ø–µ–ª–∞ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å - –∏–∑–º–µ–Ω–µ–Ω–∏–µ `sampler` –≤ `DataLoader`_

